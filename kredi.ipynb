{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f952cb9-3550-4765-a6af-b929d636fdd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Faz 1: Hazırlık ve Veri Seti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3d9bf6-fe38-40f6-bd97-3621e2e9ed8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Veriyi Anlama (Keşifsel Veri Analizi - EDA):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351d177b-2d38-4dd4-9705-89cd6d73c76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Bazen bu dosyada standart olmayan karakterler olabiliyor, \n",
    "# bu yüzden 'encoding' parametresini eklemek hataları önleyebilir. bu kod ile satır ve sütunların ne anlama geldiğini anladık.\n",
    "try:\n",
    "    column_descriptions = pd.read_csv('HomeCredit_columns_description.csv', encoding='utf-8')\n",
    "except UnicodeDecodeError:\n",
    "    column_descriptions = pd.read_csv('HomeCredit_columns_description.csv', encoding='latin1')\n",
    "\n",
    "\n",
    "# Pandas'ın normalde tüm satırları göstermeme limitini kaldıralım ki sözlüğümüzün tamamını görelim.\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', None) # Sütun içeriğinin tamamını göster\n",
    "\n",
    "print(\"Sütun Açıklamaları Dosyasının İçeriği:\")\n",
    "display(column_descriptions)\n",
    "\n",
    "# Ayarları daha sonra normale döndürmek istersen:\n",
    "# pd.reset_option('display.max_rows')\n",
    "# pd.reset_option('display.max_colwidth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93b0d20-def3-4cd7-b0ce-779de6eae0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Pandas'ın tüm sütunları göstermesini sağlayalım\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "print(\"Ana veri seti (application_train.csv) yükleniyor...\")\n",
    "# Bu dosya büyük olduğu için yüklenmesi birkaç saniye sürebilir.\n",
    "\n",
    "# Ana eğitim verimizi bir pandas DataFrame'e yüklüyoruz.\n",
    "# Bu yapı, veriyi tablo gibi işlememizi sağlar.\n",
    "df_train = pd.read_csv('application_train.csv')\n",
    "\n",
    "print(\"Yükleme tamamlandı!\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# 1. Verinin Boyutlarına Bakalım\n",
    "# .shape bize (satır sayısı, sütun sayısı)'nı verir.\n",
    "print(f\"Veri setinin boyutu (Satır Sayısı, Sütun Sayısı): {df_train.shape}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "\n",
    "# 2. Verinin İlk 5 Satırına Göz Atalım\n",
    "# .head() metodu, verinin genel yapısını anlamak için harikadır.\n",
    "print(\"Veri setinin ilk 5 satırı:\")\n",
    "display(df_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1dea086-532e-4678-b6af-d2b26db97b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Hedef değişkenin dağılımını analiz edelim\n",
    "print(\"Hedef Değişken (TARGET) Dağılımı:\")\n",
    "target_counts = df_train['TARGET'].value_counts()\n",
    "print(target_counts)\n",
    "\n",
    "print(\"\\nYüzdesel Dağılım:\")\n",
    "target_percentages = df_train['TARGET'].value_counts(normalize=True) * 100\n",
    "print(target_percentages)\n",
    "\n",
    "# Bu dağılımı görselleştirelim\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.countplot(x='TARGET', data=df_train)\n",
    "plt.title('Kredi Geri Ödeme Durumu Dağılımı\\n (0: Sorunsuz Ödeme, 1: Ödeme Güçlüğü)', fontsize=14)\n",
    "plt.xlabel('Hedef Değişken (TARGET)', fontsize=12)\n",
    "plt.ylabel('Müşteri Sayısı', fontsize=12)\n",
    "\n",
    "# Grafiği kaydet (opsiyonel)\n",
    "plt.savefig('hedef_degisken_dagilimi.png')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4155fbfb-3c04-40c6-8aad-9ac456bd3d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Her sütundaki eksik değerlerin toplamını hesapla\n",
    "missing_values = df_train.isnull().sum()\n",
    "\n",
    "# Eksik değerlerin yüzdesini hesapla\n",
    "missing_percentage = (missing_values / len(df_train)) * 100\n",
    "\n",
    "# İkisini birleştirip bir DataFrame oluştur\n",
    "missing_info = pd.DataFrame({'Eksik Değer Sayısı': missing_values, 'Yüzde (%)': missing_percentage})\n",
    "\n",
    "# Sadece eksik veri içeren sütunları göster ve yüzdesine göre büyükten küçüğe sırala\n",
    "missing_info_sorted = missing_info[missing_info['Eksik Değer Sayısı'] > 0].sort_values(by='Yüzde (%)', ascending=False)\n",
    "\n",
    "print(\"Eksik Veri İçeren Sütunlar (Yüzdeye Göre Sıralı):\")\n",
    "display(missing_info_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60422e6-9dc9-4cf4-9eb8-d9196841f566",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# TARGET=1 (ödeme güçlüğü çekenler) için kredi miktarının dağılımı\n",
    "sns.kdeplot(df_train.loc[df_train['TARGET'] == 1, 'AMT_CREDIT'], label='Target == 1', color='red')\n",
    "\n",
    "# TARGET=0 (sorunsuz ödeyenler) için kredi miktarının dağılımı\n",
    "sns.kdeplot(df_train.loc[df_train['TARGET'] == 0, 'AMT_CREDIT'], label='Target == 0', color='green')\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('Kredi Miktarı (AMT_CREDIT)', fontsize=12)\n",
    "plt.ylabel('Yoğunluk', fontsize=12)\n",
    "plt.title('Kredi Miktarının Müşteri Risk Durumuna Göre Dağılımı', fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0c53b2-062c-426e-a2a3-f9cf5a18c2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grafiğin Yorumlanması\n",
    "#Benzer Dağılımlar: İlk bakışta en çok göze çarpan şey, iki grubun dağılımının (kırmızı ve yeşil çizgiler) genel olarak birbirine oldukça benzemesidir.\n",
    "#Her iki grup da en çok düşük miktarlı krediler çekiyor ve kredi miktarı arttıkça o krediyi çeken müşteri sayısı azalıyor (sağa doğru uzun bir kuyruk var).\n",
    "#İnce Bir Fark: Ancak biraz daha dikkatli bakarsak, kırmızı çizginin (riskli müşteriler, TARGET=1) tepe noktasının, yeşil çizgiye (risksiz müşteriler, TARGET=0) göre çok az daha solda olduğunu görebiliriz. \n",
    "#Bu, ödeme güçlüğü çekenler arasında çok düşük miktarlı kredi çekenlerin oranının, sorunsuz ödeyenlere göre bir tık daha fazla olabileceğini ima ediyor.\n",
    "#En Önemli Çıkarım: Bu iki dağılım arasında keskin ve net bir ayrım yok. Bu bize şunu söylüyor: Sadece AMT_CREDIT (kredi miktarı) sütununa bakarak bir müşterinin riskli olup olmadığına kesin olarak karar vermek çok zor. \n",
    "#Demek ki modelimizin doğru karar verebilmesi için bu özellik tek başına yeterli olmayacak; birçok farklı özelliği bir arada değerlendirmesi gerekecek. İşte bu yüzden 122 tane özelliğimiz var!\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5522cf-b652-43df-95da-430e7390f793",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Faz 2: Model Geliştirme\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3c6336-9027-468b-b9d9-718939fef3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Veri Ön İşleme (Preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc5095d-c565-4b65-b553-150bf1129394",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bu fazda yapacaklarımız:\n",
    "\n",
    "#Sütunları Temizleme: %50'den fazla eksik veriye sahip olan ve modelimize faydası olmayacak sütunları veri setinden çıkaracağız.\n",
    "#Kategorik Verileri Sayısallaştırma: NAME_CONTRACT_TYPE (Cash loans/Revolving loans) veya CODE_GENDER (M/F) gibi metin içeren sütunları, \n",
    "#modellerin anlayabileceği sayılara (0, 1 gibi) dönüştüreceğiz. Buna \"Encoding\" diyoruz..\n",
    "#Kalan Eksik Verileri Doldurma: Orta ve az seviyede eksik veriye sahip sütunlardaki boşlukları, \n",
    "#ortalama, medyan veya \"Bilinmiyor\" gibi stratejilerle doldurulacak (Imputation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea55f2a-ddc5-4edb-83bb-5cda31a149f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Başlamadan önce veri setimizin ilk boyutunu hatırlayalım\n",
    "print(f\"Temizlik öncesi veri seti boyutu (Satır, Sütun): {df_train.shape}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Her sütundaki eksik değerlerin oranını (yüzdesini değil, 0-1 arası) hesaplayalım\n",
    "missing_ratios = df_train.isnull().sum() / len(df_train)\n",
    "\n",
    "# Bu oranların %50'den (yani 0.5'ten) büyük olduğu sütunları bulalım\n",
    "columns_to_drop = missing_ratios[missing_ratios > 0.5].index\n",
    "\n",
    "print(f\"Silinecek sütun sayısı: {len(columns_to_drop)}\")\n",
    "print(\"Bu sütunlar şunlar:\")\n",
    "# print(columns_to_drop.tolist()) # Eğer silinecek sütunların listesini görmek istersen bu satırı aktif et\n",
    "\n",
    "# Belirlenen sütunları 'axis=1' (sütun bazında) diyerek veri setinden silelim\n",
    "df_train_cleaned = df_train.drop(columns = columns_to_drop)\n",
    "\n",
    "# Temizlik sonrası yeni boyutu kontrol edelim\n",
    "print(\"-\" * 50)\n",
    "print(f\"Temizlik sonrası YENİ veri seti boyutu: {df_train_cleaned.shape}\")\n",
    "print(\"\\nİşlem başarılı! Artık daha temiz bir veri setine sahibiz.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54ecd55-bb40-4992-968a-10a2ba9eab14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bir önceki adımda oluşturduğumuz df_train_cleaned'i kullanalım\n",
    "# Önce kategorik ve sayısal sütunları ayıralım\n",
    "# Not: TARGET sütunu hedefimiz olduğu için onu özelliklerden ayrı tutuyoruz.\n",
    "df_processed = df_train_cleaned.drop(columns=['TARGET'])\n",
    "y = df_train_cleaned['TARGET'] # Hedef değişkeni y'ye atadık\n",
    "\n",
    "# Kategorik sütunları bulalım\n",
    "categorical_cols = df_processed.select_dtypes(include=['object']).columns\n",
    "\n",
    "# One-Hot Encoding işlemini yapalım\n",
    "# Bu işlem metin içeren sütunları 0'lar ve 1'lerden oluşan yeni sütunlara çevirir\n",
    "df_processed_encoded = pd.get_dummies(df_processed, columns=categorical_cols, dummy_na=False) # dummy_na=False ile NaN'lar için ayrı sütun oluşturmuyoruz\n",
    "\n",
    "print(f\"One-Hot Encoding öncesi sütun sayısı: {df_processed.shape[1]}\")\n",
    "print(f\"One-Hot Encoding sonrası sütun sayısı: {df_processed_encoded.shape[1]}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Şimdi, tüm veri seti sayısal hale geldi.\n",
    "# Kalan eksik değerleri (NaN) medyan ile dolduralım.\n",
    "# scikit-learn kütüphanesinden SimpleImputer'ı kullanalım\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Medyan stratejisi, aykırı değerlerden daha az etkilendiği için genellikle daha güvenlidir.\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "\n",
    "# Imputer'ı eğitelim ve veriyi dönüştürelim\n",
    "df_final = pd.DataFrame(imputer.fit_transform(df_processed_encoded), columns=df_processed_encoded.columns)\n",
    "\n",
    "print(\"Eksik verileri doldurduktan sonraki durum:\")\n",
    "# Kalan toplam eksik veri sayısını kontrol edelim\n",
    "print(f\"Son veri setindeki toplam eksik veri sayısı: {df_final.isnull().sum().sum()}\")\n",
    "print(f\"Nihai veri setimizin boyutu (Satır, Sütun): {df_final.shape}\")\n",
    "print(\"\\nTebrikler! Veri setimiz artık modelleme için tamamen temiz ve hazır!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93235972-c27b-4a9c-b843-e4e46523e5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#80 özellik sütunumuz vardı.\n",
    "#Metin içeren kategorik sütunları One-Hot Encoding ile sayısala çevirdik ve bu işlem sütun sayımızı 193'e çıkardı.\n",
    "#Kalan tüm eksik değerleri medyan ile doldurduk ve veri setimizde 0 eksik değer kaldı.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee32d8b-737d-4d6c-aceb-ae974e2549a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Faz 3 - Model Geliştirme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1cc70e-64b2-46b6-82ad-f3d6d4e8de32",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af8ae80-b371-450a-a692-2a7878eb8897",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# 1. Veriyi Eğitim ve Test Setlerine Ayırma\n",
    "# X -> Özelliklerimiz (df_final)\n",
    "# y -> Hedefimiz (TARGET)\n",
    "# test_size=0.2 -> Verinin %20'sini test için ayır\n",
    "# stratify=y -> Ayırma işlemi yapılırken eğitim ve test setlerindeki %8'lik TARGET oranını koru. Bu çok önemli!\n",
    "# random_state=42 -> Her seferinde aynı ayırma işleminin yapılmasını sağlar.\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_final, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print(\"Veri setleri ayrıldı:\")\n",
    "print(f\"Eğitim seti boyutu: {X_train.shape}\")\n",
    "print(f\"Test seti boyutu: {X_test.shape}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# 2. Dengesiz veri seti için 'scale_pos_weight' parametresini hesaplama\n",
    "# Bu parametre, azınlık sınıfına (TARGET=1) daha fazla önem verilmesini sağlar.\n",
    "scale_pos_weight = y_train.value_counts()[0] / y_train.value_counts()[1]\n",
    "print(f\"Dengesizlik oranı (scale_pos_weight): {scale_pos_weight:.2f}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "\n",
    "# 3. XGBoost Modelini Tanımlama ve Eğitme\n",
    "print(\"XGBoost modeli eğitiliyor...\")\n",
    "\n",
    "# Modeli, hesapladığımız parametre ile tanımlıyoruz.\n",
    "# n_estimators, modelin kaç tane ağaç kuracağını belirtir. İlk deneme için 100 iyi bir başlangıç.\n",
    "# max_depth, her ağacın ne kadar derin olabileceğini kontrol eder. Overfitting'i önlemeye yardımcı olur.\n",
    "model = XGBClassifier(n_estimators=200, max_depth=5, scale_pos_weight=scale_pos_weight, random_state=42, n_jobs=-1)\n",
    "\n",
    "# Modeli eğitim verileriyle eğitiyoruz. Bu işlem birkaç dakika sürebilir.\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Model başarıyla eğitildi!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b249bffa-649e-433f-9792-03dccc82c77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Değerlendirme aşaması"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49396460-9448-4e61-9fa4-9e4fa4c70e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Test verisi üzerinde tahmin yapma\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_proba = model.predict_proba(X_test)[:, 1] # ROC AUC için olasılık değerleri gerekir\n",
    "\n",
    "# 2. Performans metriklerini hesaplama\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "print(\"--- Model Performans Metrikleri ---\")\n",
    "print(f\"Doğruluk (Accuracy): {accuracy:.4f}\")\n",
    "print(f\"Kesinlik (Precision): {precision:.4f}\")\n",
    "print(f\"Duyarlılık (Recall): {recall:.4f}\")\n",
    "print(f\"ROC AUC Skoru: {roc_auc:.4f}\")\n",
    "print(\"-\" * 35)\n",
    "\n",
    "# 3. Karmaşıklık Matrisini (Confusion Matrix) oluşturma ve görselleştirme\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['Tahmin: Risksiz (0)', 'Tahmin: Riskli (1)'],\n",
    "            yticklabels=['Gerçek: Risksiz (0)', 'Gerçek: Riskli (1)'])\n",
    "plt.ylabel('Gerçek Değer')\n",
    "plt.xlabel('Tahmin Edilen Değer')\n",
    "plt.title('Karmaşıklık Matrisi (Confusion Matrix)', fontsize=15)\n",
    "plt.show()\n",
    "\n",
    "# 4. Sınıflandırma Raporu\n",
    "print(\"\\n--- Sınıflandırma Raporu ---\")\n",
    "print(classification_report(y_test, y_pred, target_names=['Risksiz (0)', 'Riskli (1)']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979136a2-cdd7-4c15-8a51-c867206fae5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duyarlılık (Recall): Gerçekten riskli olan müşterilerin yüzde kaçını doğru tespit edebildiğimizi gösterir. Yüksek olması, batık kredi riskini kaçırmadığımız anlamına gelir ve genellikle bu tür problemler için en önemli metriklerden biridir.\n",
    "\n",
    "# Kesinlik (Precision): \"Riskli\" olarak tahmin ettiklerimizin yüzde kaçının gerçekten riskli olduğunu gösterir. Yüksek olması, sağlıklı müşterileri yanlışlıkla \"riskli\" olarak etiketleme oranımızın düşük olduğu anlamına gelir.\n",
    "\n",
    "# Doğruluk (Accuracy): Tüm tahminlerin (riskli/risksiz) genel olarak yüzde kaçının doğru olduğunu gösterir. Dengesiz veri setlerinde (bizimki gibi) yanıltıcı olabileceği için tek başına güvenilmez.\n",
    "\n",
    "# ROC AUC Skoru: Modelin, riskli ve risksiz müşteri profillerini birbirinden genel olarak ne kadar iyi ayırt edebildiğini ölçer. 1'e ne kadar yakınsa, modelin ayırt etme gücü o kadar iyidir (0.5 rastgele tahmindir)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d3dd25-336e-4bd1-9f2b-ecb53ec4bdb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dff7d6a-12b4-4606-9ce2-176a44b49348",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "# SHAP'ın JavaScript görsellerini not defterinde düzgün göstermesi için bu satırı çalıştıralım\n",
    "shap.initjs()\n",
    "\n",
    "print(\"SHAP değerleri hesaplanıyor. Bu işlem birkaç dakika sürebilir...\")\n",
    "\n",
    "# Modelimizin bir ağaç tabanlı model (XGBoost) olduğunu belirten bir \"Açıklayıcı\" (Explainer) oluşturuyoruz.\n",
    "explainer = shap.TreeExplainer(model)\n",
    "\n",
    "# Test setimiz üzerinden SHAP değerlerini hesaplıyoruz.\n",
    "# Bu işlem tüm test seti için uzun sürebileceğinden, genellikle daha hızlı sonuç almak için bir alt küme kullanılır.\n",
    "# Ancak şimdilik tüm test setiyle deneyelim.\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "print(\"Hesaplama tamamlandı. Özet grafiği oluşturuluyor...\")\n",
    "\n",
    "# Modelimiz için en önemli özellikleri gösteren özet grafiği (summary plot)\n",
    "# Bu grafik, hangi özelliğin tahminleri ne yönde ve ne kadar etkilediğini gösterir.\n",
    "shap.summary_plot(shap_values, X_test, plot_type=\"dot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b82b326-790e-4bae-9e48-b03f9e0310f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "# Daha önce hesapladığımız explainer ve shap_values'ı kullanacağız\n",
    "\n",
    "# 1. Başarıyla \"Riskli\" olarak tahmin edilen bir müşteri bulalım\n",
    "# Gerçek değeri 1 ve tahmin edilen değeri 1 olan ilk müşterinin index'ini alalım\n",
    "true_positive_customer_index = X_test[(y_test == 1) & (y_pred == 1)].index[0]\n",
    "# Bu index'in test setindeki yerini bulalım\n",
    "true_positive_loc = X_test.index.get_loc(true_positive_customer_index)\n",
    "\n",
    "print(f\"--- REDDEDİLEN Müşteri Analizi (Index: {true_positive_customer_index}) ---\")\n",
    "print(\"Bu grafikte kırmızı oklar riski ARTIRAN, mavi oklar ise riski AZALTAN faktörleri gösterir.\")\n",
    "# Bu müşteri için Force Plot'u oluşturalım\n",
    "shap.force_plot(explainer.expected_value, shap_values[true_positive_loc,:], X_test.loc[true_positive_customer_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da395993-7926-48f7-b99d-f705d653cbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Başarıyla \"Risksiz\" olarak tahmin edilen bir müşteri bulalım\n",
    "# Gerçek değeri 0 ve tahmin edilen değeri 0 olan ilk müşterinin index'ini alalım\n",
    "true_negative_customer_index = X_test[(y_test == 0) & (y_pred == 0)].index[0]\n",
    "# Bu index'in test setindeki yerini bulalım\n",
    "true_negative_loc = X_test.index.get_loc(true_negative_customer_index)\n",
    "\n",
    "print(f\"\\n\\n--- ONAYLANAN Müşteri Analizi (Index: {true_negative_customer_index}) ---\")\n",
    "print(\"Bu grafikte kırmızı oklar riski ARTIRAN, mavi oklar ise riski AZALTAN faktörleri gösterir.\")\n",
    "# Bu müşteri için Force Plot'u oluşturalım\n",
    "shap.force_plot(explainer.expected_value, shap_values[true_negative_loc,:], X_test.loc[true_negative_customer_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab212443-7039-4b5e-98a3-eb08b7b5dad4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
